{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiOtGGbyRHcjroUD63/U6R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/23520052/DoAnDuLieuLon/blob/main/4_Demo_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7j7opn5iorVm"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# --- C·∫§U H√åNH TRANG ---\n",
        "st.set_page_config(page_title=\"ABSA Demo\", page_icon=\"üçú\", layout=\"centered\")\n",
        "\n",
        "st.title(\"üçú Ph√¢n t√≠ch c·∫£m x√∫c Nh√† h√†ng\")\n",
        "st.caption(\"D·ª± √°n Big Data: PhoBERT + Back-Translation\")\n",
        "\n",
        "# --- LOAD MODEL T·ª™ DRIVE ---\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    # ƒê∆Ø·ªúNG D·∫™N T·ªöI TH∆Ø M·ª§C CH·ª®A MODEL TRONG DRIVE\n",
        "    model_path = '/content/drive/My Drive/ABSA_Project/Model_Final'\n",
        "\n",
        "    # Load Tokenizer & Model (T·ª± ƒë·ªông nh·∫≠n di·ªán safetensors ho·∫∑c bin)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    return tokenizer, model\n",
        "\n",
        "try:\n",
        "    with st.spinner('ƒêang kh·ªüi ƒë·ªông AI... (M·∫•t kho·∫£ng 30s)'):\n",
        "        tokenizer, model = load_model()\n",
        "    st.success(\"H·ªá th·ªëng s·∫µn s√†ng!\", icon=\"‚úÖ\")\n",
        "except Exception as e:\n",
        "    st.error(f\"L·ªói load model: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "# --- GIAO DI·ªÜN ---\n",
        "input_text = st.text_area(\"Nh·∫≠p nh·∫≠n x√©t:\", height=100,\n",
        "                          placeholder=\"V√≠ d·ª•: ƒê·ªì ƒÉn ngon nh∆∞ng gi√° h∆°i ch√°t.\")\n",
        "\n",
        "aspect = st.selectbox(\"Ch·ªçn kh√≠a c·∫°nh:\",\n",
        "                     [\"FOOD#QUALITY\", \"SERVICE#GENERAL\",\n",
        "                      \"AMBIENCE#GENERAL\", \"RESTAURANT#PRICES\"])\n",
        "\n",
        "if st.button(\"Ph√¢n t√≠ch ngay\", type=\"primary\"):\n",
        "    if not input_text:\n",
        "        st.warning(\"Vui l√≤ng nh·∫≠p n·ªôi dung!\")\n",
        "    else:\n",
        "        # X·ª≠ l√Ω input theo chu·∫©n PhoBERT\n",
        "        full_input = f\"{aspect} {tokenizer.sep_token} {input_text}\"\n",
        "        inputs = tokenizer(full_input, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = F.softmax(outputs.logits, dim=1)\n",
        "            confidence, pred = torch.max(probs, dim=1)\n",
        "\n",
        "        # Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
        "        labels = {0: \"TI√äU C·ª∞C üò°\", 1: \"TRUNG L·∫¨P üòê\", 2: \"T√çCH C·ª∞C üòç\"}\n",
        "        colors = {0: \"#ffcccc\", 1: \"#fff4cc\", 2: \"#ccffcc\"}\n",
        "        idx = pred.item()\n",
        "\n",
        "        st.markdown(f\"\"\"\n",
        "        <div style=\"padding: 20px; background-color: {colors[idx]}; border-radius: 10px; text-align: center;\">\n",
        "            <h2 style=\"color: #333; margin:0;\">{labels[idx]}</h2>\n",
        "            <p>ƒê·ªô tin c·∫≠y: <b>{confidence.item():.1%}</b></p>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ch·∫°y ng·∫ßm server\n",
        "!nohup streamlit run app.py &\n",
        "\n",
        "# ‚ö†Ô∏è H∆Ø·ªöNG D·∫™N:\n",
        "# 1. ƒêƒÉng k√Ω t√†i kho·∫£n mi·ªÖn ph√≠ t·∫°i: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "# 2. Copy token c·ªßa b·∫°n v√† thay th·∫ø v√†o d√≤ng b√™n d∆∞·ªõi:\n",
        "\n",
        "# Thay d√≤ng ch·ª©a token th·∫≠t b·∫±ng d√≤ng n√†y:\n",
        "ngrok.set_auth_token(\"D√ÅN_M√É_TOKEN_NGROK_C·ª¶A_B·∫†N_V√ÄO_ƒê√ÇY\")\n",
        "\n",
        "url = ngrok.connect(8501).public_url\n",
        "print(f\"üöÄ LINK DEMO: {url}\")"
      ],
      "metadata": {
        "id": "3X6gOi5Et-hn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}